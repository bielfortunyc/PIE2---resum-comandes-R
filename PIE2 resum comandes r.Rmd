---
title: "RESUM PIE2 - R commands"
author: "PauM PauF"
date: "2023-12-27"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Comandes i exemples per llegir dades

```{r}
rep(c("16 mesos", "24 mesos"), each=3) # repetir 3 vegades cada element 
rep(c("0", "0.45", "0.75"), times=2) # repetir 2 vegades el vector sencer

dades = matrix(c(2500, 50, 10,
                 2700, 70, 17,
                 2900, 100, 30, 
                 3100, 60, 21), # resum de les dades 
               ncol = 3, # ncol per indical el nombre de columnes
               byrow = True) # byrow = True  (False per dafault) per omplir la matriu per files                                   # /columnes

```

```{r}
temps = factor(rep(c("16 mesos", "24 mesos"), each=3))
temps
dosi = factor(rep(c("0", "0.45", "0.75"), times=2))
dosi
```

Per exemple, a l'exercici 6 de glm, les dades les podem llegir de la
següent manera:

```{r}
ntumors = c(1, 3, 7, 20, 98, 118)
nratolins = c(205, 304, 193, 762, 888, 587)
cbind(ntumors, nratolins)
temps = factor(rep(c("16 mesos", "24 mesos"), each=3))
dosi = factor(rep(c("0", "0.45", "0.75"), times=2))

dades = data.frame(periode = temps, 
                   dosi = dosi,
                   ntumors = ntumors,
                   nratolins = nratolins)
```
head(dades) ens mostra les dades que acabem de llegir. Sol donar-ne les primeres línies.


## Plots

llibreries: library(ggplot2) library(moderndive)

```{r}
library(ggplot2)
library(moderndive)
```

#### Sense suposar interacció

```{r}
ggplot(iris) +
  aes(x = Sepal.Width, y = Sepal.Length, color = Species) +
  geom_parallel_slopes(se=FALSE) +
  geom_point()
```

#### Suposant interacció

```{r}
ggplot(iris) +
  aes(x = Sepal.Width, y = Sepal.Length, color = Species) +
  geom_smooth(se = FALSE, method = "lm") +
  geom_point()
```

#### Boxplot segons tipus

```{r}
# boxplot bonic
ggplot(iris, aes(Species, Sepal.Length)) +
  geom_boxplot(aes(fill = Species)) +
  theme_minimal() +
  theme(legend.position = "top")

# boxplot cutre pero que en escència és el mateix.
boxplot(Sepal.Length ~ Species, data=iris)
```

#### Separar plots segons alguna variable (en comptes de fer-ho per colors, per exemple):

```{r}
ggplot(iris) + 
  aes(x = Sepal.Width, y = Sepal.Length) + 
  geom_point() + 
  facet_wrap(~Species)
```

#### Veure algunes mostres en concret a un plot:

(si tenim les mostres que volen per índexs):

```{r}
indexs = c(69, 106, 107, 119, 123, 131, 132, 136) 
mostres_cook <- irisdat4[irisdat4$X %in% indexs, ] 
ggplot(iris) + …. + gplot + geom_text(data = mostres_cook, aes(label = X), vjust = -1)

```

#### ggpairs:

library(GGally) ggpairs(irisdat4)

## Models i funcions randoms

-- lm ---- glm ----- logit vs provit ----- kruskal test ----- aov -----
anova() -------- vif

## Interpretació summary

```{r}
model2 = lm(Sepal.Length ~ Sepal.Width + Species, data=irisdat4)
summary(model2)
```

-   Estimate: valor obtingut de l'estimació dels coeficients del model

-   t value: valor de l'estadístic per a la prova d'hipòtesi H0: coeff =
    0

-   Pr(\>\|t\|): p-valor de la prova d'hipòtesi H0: coeff = 0

-   Residual standard error: desviació estàndard dels resiuds. Quan ens
    demanen l'estimació de la VARIÀNCIA del model (o variància
    residual), hem de calcular el quadrat d'aquest valor.

-   Multiple R-squared: part de la variabilitat de la variable resposta
    és explicada pel model. És una manera de calcular la bondat d'ajust
    del model a les dades.

-   Adj. R-squared: bondat d'ajust "corregida"; penalitza tenir massa
    paràmetres. Per comparar dos models linials aniguats l'un a l'altre
    (que un tingui els mateixos paràmetres que l'altre i algun més),
    comparem els R-squared adj., i ens quedem amb el model que tingui un
    R-sqared adj. més gran.

-   F-statistic.., p-value.. : estadístic i p-valor de la prova
    d'hipòtesi que compara el nostre model amb el model nul (H0: beta1 =
    beta2 = ... = 0). Ens interessa tenir un F-statistic GRAN (o bé un
    p-valor petit).

-   Pel que fa als residus, ens interessa veure que estan centrats al 0
    (que el residu màxim i el mínim siguin relativament simètrics, i el
    mateix pels quantils).

## Plots (residus, leverage, cook) i com haurien de ser

#### Resudial vs Fitted

```{r}
plot(model2, which=1)
```

Aquí veiem els valors dels resiuds en funció dels valors ajustats (valor
de la variable resposta quan s'evaluen amb les explicatives). Aquí
hauríem d'observar:

-   Els valors dels residus no hauríen de dependre dels valors ajustats.
    És a dir, no hauríem de veure cap tendència de
    creixement/decreixement a la gràfica -- la línia vermella hauria de
    ser plana.

-   La variabilitat dels resiuds hauria de ser sempre igual (hipòtesi
    d'homoscedasticitat) (en aquest cas per exemple, la variança
    augmenta una mica cap a valors més grans dels fitted values, cosa
    que no hauria de passar). Això es veu similarment a la gràfica de
    Scale-Location.

#### Normal Q-Q

```{r}
plot(model2, which=2)
```

Aquí ens compara els residus (estandaritzats) respecte la distribució
Normal. Per a aque es compleixi l'hipòtesi de normalitat dels residus,
hauriem de veure que els residus tendeixen a la distribució normal. En
aquest cas, no ho compleixen gaire.

#### Scale-Location

```{r}
plot(model2, which=3)
```

Aquí podem veure també si els residus estan equitativament repartits en
funció dels fitted values:

-   NO hauríem de veure cap tendència de creixement o decreixement, ja
    que indicaria que la variància dels resiuds varia en funció dels
    fitted values

#### Residus estandaritzats

```{r}
plot(abs(rstandard(model2)))
abline(a=2, b=0,lty=2)
```

(també es poden veure sense el valor absolut): plot(rstudent(model2))
abline(h=c(-2,0,2),lty=2)

Aquí hauríem de veure que es compleix l'hipòtesi de normalitat; hauríem
de tenir el 95% dels residus dins de l'intèrval [-2, 2] (o [0, 2] si ens
mirem el valor absolut dels residus), i un 5% dels residus fora d'aquest
intèrval.

#### Residuals vs Leverage

```{r}
plot(model2, which=5)
```

Podem veure si hi ha mostres influents --\> si hi ha mostres que tenen
un leverage i una cook's distance gran, podrien ser influents, per tant
hauriem de veure els residus acumulats cap al centre, i després sempre
en podem tenir que tinguin un leverage gran però que el residu sigui
petit, o que el residu sigui més gran però que tingui leverage petit.
Tot i així no és la millor gràfica per veure els valors del leverage i
de la cook's distance de les mostres.

#### Cook's distance

```{r}
n = nrow(irisdat4)  #nombre de mostres amb que hem ajustat el model
plot(cooks.distance(model2))
abline(h=c(0,4/n),lty=2)  
```

OJO, que aquí estem assumint que fem servir la condició 4/n com a cook's
distance gran. Sempre es pot canviar la posició de la linia
(abline(...)) per si hem de fer servir una altra confició. Aquí
simplement veiem si hi ha mostres que tenen una cook's distance més gran
que 4/n, i com a tal si són influents o no.

Per veure els índexs de les mostres que tenen una cook's distance més
gran que 4/n, podem fer-ho així:

```{r}
cook = cooks.distance(model2) > 4/n
which(cook)
```

Per treure-les del data set:

```{r}
irisdat4.1 <- irisdat4[- c(69, 106, 107, 119, 123, 131, 132, 136),]
```

#### Leverage

```{r}
plot(hatvalues(model2), type = 'h')
```

(el leverage d'una mostra és el mateix valor que el hatvalue)

Per veure quines mostres tenen un leverage gran:

```{r}
p = ncol(model.matrix(model2))
n = nrow(irisdat4)
cond_lev = 3*p/n    #condició de leverage gran
indexs = which(hatvalues(model2)>cond_lev)
mostres = irisdat4[indexs,]
```

## Anova

Part explicada amb l'exemple dels donuts.

Llibreries que utilitzarem: emmeans, multcomp, multcompView:

```{r}
library(emmeans)
library(multcomp)
library(multcompView)
```

Carreguem les dades:

**IMPORTANT PASSAR A FACTOR**

```{r}
dough = read.csv("http://vicpena.github.io/pie2/dough.csv")

dough$type = factor(dough$type)

# model lineal
mod_lm = lm(fat ~ type, data = dough)
```

#### AOV

La comanda **aov** ens crea un model que ajusta una relació linear.
Aquest model serà l'objecte que farem servir per fer les comparacions
entre grups. A diferència d'un ajust d'un model linear "normal", aquest
objecte conté la taula anova.

```{r}
mod = aov(fat ~ type, data  = dough)
# taula anova
summary(mod)

# estimacio coeficients (els mateixos que rebrem si fem summary d'un lm normal)
coef(mod)
```

#### Emmeans

Aquesta comanda la utilitzarem perquè ens creï els IC de cada grup.
**IMPORTANT:** Se li ha de passar el model creat amb la comanda **aov**
(taula **anova**).

```{r}
comp = emmeans(mod, ~ type, level=0.95)
comp
```

A ull podem veure que hi ha diferècies entre el grup dos i quatre, i que
l'u i el tres son molt similars. Les mateixes observacions es poden fer
amb el boxplot.

#### Tukey

Per fer les múltiples comparacions del mètode tukey utilitzarem la
comanda **pairs**. Ens retorna totes les comparacions dos a dos amb
l'ordre que seguiria l'algorisme tukey.

Com més petit sigui el **p-valor**, mes diferent son els dos grups.

```{r}
pairs(comp, level = 0.95)
# cld(comp, level = 0.95)
```

La comanda cld ens comprimirà el resultat de pairs perquè sigui més
fàcil interpretar-lo.

Ens agruparà els grups que siguin significativament iguals.

```{r}
cld(comp, level = 0.95)
```

#### Kruskal 

**(no se com ens ho poden preguntar pero el victor ho va posar a una
classe)**

La prova de Kruskal la utilitzarem quan no es compleixen les suposicions
de normalitat i homogeneïtat de les variàncies requerides per fer
l'ANOVA.

Test d'hipotesi:

1.  **Hipòtesi nul·la (H0):** Les mitjanes de tots els grups són iguals.

2.  **Hipòtesi alternativa (H1):** Almenys un grup té una mediana
    diferent respecte als altres.

```{r}
kruskal.test(fat ~ type, data = dough)
```

Si $p < 0.05$ rebutgem la nul·la.



### GLM

Per veure un exemple, utilitzem l'exercici de la insecticida
```{r}
dd = read.csv2("http://vicpena.github.io/pie2/insecticida.csv")
cbind(dd$MORTS,dd$T-dd$MORTS)   
# aquestes dades estan en format taula

# a vegades, les dades es presenten d'una altra manera:
# cada fila representa un individu diferent
# PROBIT MODEL #
        
m1 = glm(cbind(MORTS,T-MORTS)~log(DOSI),
         family=binomial(link="probit"),data=dd)
summary(m1)

```
cbind(dd$MORTS,dd$T-dd$MORTS)  genera una taula on apareix la quantitat de morts i no morts per dosi. 
En aquest cas el model es crea utilitzant la taula anterior com a variable resposta i el log de la DOSI com a explicativa, a més com es tracta de dades binàries s'utilitza la família binomial i s'ha usat el link probit per transformar la probabilitat p en un valor continu que pot estendre's des de menys infinit a infinit..  

Volem veure com de bo és el model, si el model és bo, la suma dels quadrats dels residus de pearson dividit per n-p hauria de ser proper a 1. 
```{r}
# n: mida de les mostres
# p = nombre de betas
n = 10
p = 2
pear = resid(m1, type = "pearson")
sum(pear^2)/(n-p)
```

Si el model és bo, la suma dels quadrats dels residus de pearson hauria d'aproximar-se a una chisq amb n-p graus de llibertat.
```{r}
# H0: model correcte
# H1: model no correcte
# rebutgem per valors de residus grans 
qchisq(0.95, n-p)
sum(pear^2)
# Conclusió: no rebutgem H0.
```

En el nostre cas de dades binàries volem predir la probabilitat de morir segons la dosi. Això ho farem de la següent manera.
```{r}
pred = predict(m1,type="response")
cbind(dd, pred)
plot(log(dd$DOSI), dd$MORTS/dd$T)
lines(log(dd$DOSI), pred)
```
Podem veure en el plot com de bones són les nostres prediccions comparant-les amb les dades reals.




Creem ara un model però amb el link logit
```{r}

m2 = glm(cbind(MORTS,T-MORTS)~log(DOSI),
         family=binomial(link="logit"),data=dd)
summary(m2)
```

Pel model m2 podem fer el mateix que hem fet amb el model m1(plots, prediccions, comparar residus pearson...) per veure si és bo, però podem decidir quin és millor comparant els AIC, que és una mesura utilitzada en estadística per a la selecció de models que penalitza la complexitat del model (nombre de paràmetres) i premia l'ajust del model a les dades..
```{r}
AIC(m1) # probit
AIC(m2) # logistic
```

Veiem que el model logit és lleugerament millor ja que és més petit.



Per veure la predicció d'algun grup concret de les dades usarem l'exemple de l'alcohol.

```{r}
edat = c("25-34", "25-34",
         "35-44", "35-44",
         "45-54", "45-54",
         "55-64", "55-64",
         "65-74", "65-74",
         "75+", "75+")

consum = rep(c("alta", "baixa"), 6)

si = c(1, 0, 4, 5, 25, 21, 42,
       34, 19, 36, 5, 8)  
no = c(9, 106, 26, 164, 29, 138,
       27,  139, 18, 88,
       0, 31)

dades = data.frame(edat, consum, si, no)
dades

mod_logistic = glm(cbind(si, no) ~ edat + consum, 
                   family = binomial,
data = dades)



# Quina és la probabilitat predita
# per algú que no begui alcohol i tingui
# una edat entre 55 i 64 anys
newdata = data.frame(edat = "55-64", consum = "baixa")
predict(mod_logistic, newdata = newdata,
        type = "response")
```
Simplement creem un nou data.frame seleccionant les dades que ens interessen i fem pred del model amb les noves dades.


Veiem un altre exemple, el dels pingüins.
```{r}
library(palmerpenguins)
data(penguins)

head(penguins)

# excloem observacions mancants
penguins = na.omit(penguins)

# objectiu: predir sexe 
# dels pingüins donades les altres variables


# ajustem un model logístic amb totes les variables
mod_full = glm(sex ~ . , data = penguins,
               family = binomial)
summary(mod_full)
#si no especifiquem el link és logit.
#Les variables amb coeficient positiu indiquen que aquestes fan que augmenti l'observació a ser predita com a mascle.
```
En aquest cas tenim diversos paràmetre poc significatius, llavors podem fer el següent:
```{r}
# fem backward selection amb AIC per a seleccionar
# un subconjunt de variables
mod_bwd = step(mod_full)
summary(mod_bwd)
```
Així ens quedem amb un subconjunt de variables les quals hem anat traient poc a poc fins que l'AIC augmenta.
Podem ara graficar les nostres prediccions.
```{r}
penguins$preds = predict(mod_bwd, type = "response")
ggplot(penguins) +
    aes(x = preds, y = sex) +
        geom_boxplot()
```
Veiem que les nostres prediccions de mascle es troben bastant acumulades a la banda contraria de les prediccions de femella, podem convertir les previsions, que són probabilitats, en "home" o "dona".
```{r}
# a través de la regla
# mascle si probabilitat prevista > 0.5
# femella altrament
penguins$preds_sex = ifelse(penguins$preds > 0.5,
                            "male", "female")
# fem una taula de preds_sex (predicció) contra sex (dades)
tab = table(penguins$preds_sex, penguins$sex)
tab
```
Veiem que les prediccions s'han equivocat en les 27 observacions de la diagonal, això representa una precisió del
```{r}
sum(diag(tab))/sum(tab)
```

Exemple és el dels ratolins per comparar model additiu i interactiu.
```{r}
ntumors = c(1, 3, 7,
            20, 98, 118)
nratolins = c(205, 304, 193,
              762, 888, 587)
cbind(ntumors, nratolins)

periode = factor(rep(c("16 mesos", "24 mesos"), 
                  each = 3))

dosi = factor(rep(c("0", "0.45", "0.75"), 
                  times = 2))


dades = data.frame(periode = periode,
                   dosi = dosi,
                   ntumors = ntumors,
                   nratolins = nratolins)



```

Volem saber si la interacció és significativa, podem fer una prova per raó de versemblances.

```{r}
mod_ratolins = glm(cbind(ntumors, nratolins-ntumors) ~ dosi + periode,
                   data = dades,
                   family = binomial)
model.matrix(mod_ratolins)

# model amb interacció
mod_inter = glm(cbind(ntumors, nratolins-ntumors) ~ dosi*periode ,
                data = dades,
                family = binomial)
anova(mod_ratolins, mod_inter, test = "LRT")

#Amb p-valor tant gran concloem que la interacció no és significativa.

```


